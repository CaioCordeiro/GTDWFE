{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating feature selection algorithms to apply in antimicrobial-resistant genes classification in Gram-negative bacterias.\r\n",
    "\r\n",
    "Explore feature selection and evaluation algorithms to select the most important features of antimicrobial-resistant genes in Gram-negative bacterias."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import seaborn as sns\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.model_selection import cross_val_predict\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.metrics import plot_confusion_matrix\r\n",
    "from sklearn.datasets import load_iris\r\n",
    "from sklearn.model_selection import cross_validate\r\n",
    "#from feature_selection.relieff_algorithm import Relieff\r\n",
    "#from comparators.scores import get_mean_scores\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from scipy.spatial.distance import pdist, jaccard"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df = pd.read_csv(\"data/Ac_Sa_Ca_Kl_Ec/bla_all.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = load_iris()\r\n",
    "df = pd.DataFrame(data= np.c_[df['data'], df['target']],\r\n",
    "                     columns= df['feature_names'] + ['target'])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Database Handling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discretizing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def discretize(df):\r\n",
    "    for i in df.columns:\r\n",
    "        if i != \"Feature\":\r\n",
    "            df[i] = pd.qcut(df[i], q=5,  labels=False, precision=0, duplicates='drop')\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df = discretize(df)\r\n",
    "df.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       X.G1.1.1.1.  X.G1.1.1.2.  X.G1.1.1.3.  X.G1.1.1.4.  X.G1.1.1.5.  \\\n",
       "count   107.000000   107.000000   107.000000   107.000000   107.000000   \n",
       "mean      2.000000     2.000000     2.000000     2.000000     1.990654   \n",
       "std       1.434086     1.434086     1.434086     1.434086     1.430763   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "50%       2.000000     2.000000     2.000000     2.000000     2.000000   \n",
       "75%       3.000000     3.000000     3.000000     3.000000     3.000000   \n",
       "max       4.000000     4.000000     4.000000     4.000000     4.000000   \n",
       "\n",
       "       X.G1.1.1.6.  X.G1.1.1.7.  X.G1.1.1.8.  X.G1.1.1.9.  X.G1.1.1.10.  ...  \\\n",
       "count   107.000000   107.000000   107.000000   107.000000    107.000000  ...   \n",
       "mean      1.990654     1.990654     2.000000     2.000000      2.000000  ...   \n",
       "std       1.424154     1.430763     1.434086     1.434086      1.434086  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000      0.000000  ...   \n",
       "25%       1.000000     1.000000     1.000000     1.000000      1.000000  ...   \n",
       "50%       2.000000     2.000000     2.000000     2.000000      2.000000  ...   \n",
       "75%       3.000000     3.000000     3.000000     3.000000      3.000000  ...   \n",
       "max       4.000000     4.000000     4.000000     4.000000      4.000000  ...   \n",
       "\n",
       "            LC6.1       LC6.2       LC6.3       LC7.1       LC7.2       LC7.3  \\\n",
       "count  107.000000  107.000000  107.000000  107.000000  107.000000  107.000000   \n",
       "mean     2.000000    2.000000    2.000000    2.000000    2.000000    2.000000   \n",
       "std      1.434086    1.434086    1.434086    1.434086    1.434086    1.434086   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "50%      2.000000    2.000000    2.000000    2.000000    2.000000    2.000000   \n",
       "75%      3.000000    3.000000    3.000000    3.000000    3.000000    3.000000   \n",
       "max      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
       "\n",
       "            LC8.1       LC8.2       LC8.3      Output  \n",
       "count  107.000000  107.000000  107.000000  107.000000  \n",
       "mean     2.000000    2.000000    2.000000    0.401869  \n",
       "std      1.434086    1.434086    1.434086    0.492583  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      1.000000    1.000000    1.000000    0.000000  \n",
       "50%      2.000000    2.000000    2.000000    0.000000  \n",
       "75%      3.000000    3.000000    3.000000    1.000000  \n",
       "max      4.000000    4.000000    4.000000    1.000000  \n",
       "\n",
       "[8 rows x 622 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X.G1.1.1.1.</th>\n",
       "      <th>X.G1.1.1.2.</th>\n",
       "      <th>X.G1.1.1.3.</th>\n",
       "      <th>X.G1.1.1.4.</th>\n",
       "      <th>X.G1.1.1.5.</th>\n",
       "      <th>X.G1.1.1.6.</th>\n",
       "      <th>X.G1.1.1.7.</th>\n",
       "      <th>X.G1.1.1.8.</th>\n",
       "      <th>X.G1.1.1.9.</th>\n",
       "      <th>X.G1.1.1.10.</th>\n",
       "      <th>...</th>\n",
       "      <th>LC6.1</th>\n",
       "      <th>LC6.2</th>\n",
       "      <th>LC6.3</th>\n",
       "      <th>LC7.1</th>\n",
       "      <th>LC7.2</th>\n",
       "      <th>LC7.3</th>\n",
       "      <th>LC8.1</th>\n",
       "      <th>LC8.2</th>\n",
       "      <th>LC8.3</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.990654</td>\n",
       "      <td>1.990654</td>\n",
       "      <td>1.990654</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.401869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.434086</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>1.430763</td>\n",
       "      <td>1.424154</td>\n",
       "      <td>1.430763</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>...</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>1.434086</td>\n",
       "      <td>0.492583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 622 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "y = df['target']\r\n",
    "X = df.drop(['target'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Separating the model target to its own variables."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dropping the 'Output' as it will be representend as the y, and 'Feature' columns from the dataframe as it's not necessary for the analysis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#df = pd.get_dummies(df, columns=[\"Feature\"])\r\n",
    "y = df[\"Output\"]\r\n",
    "X = df.drop([\"Output\",\"Feature\"], axis=1) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_mean_scores(scores: dict, name: str) -> dict:\r\n",
    "    for i in scores.keys():\r\n",
    "        scores[i] = sum(scores[i])/len(scores[i])\r\n",
    "    scores[\"name\"] = name\r\n",
    "    return scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Applying Feature Selection Algorithms.\r\n",
    "\r\n",
    "We create a copy of the dataframe to apply the feature selection algorithm."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we use the Relieff algorithm in the database of datasets to find the most relevant features to predict the target variable."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import numpy as np\r\n",
    "import sklearn_relief as relief\r\n",
    "\r\n",
    "\"implements the Relieff feature selection algorithm\"\r\n",
    "def Relieff(X, y):\r\n",
    "    return relief.RReliefF( n_features=3 ).fit_transform(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "X_relieff = X.copy(deep=True)\r\n",
    "X_relieff = Relieff(X_relieff.to_numpy(), y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we are using Pearson correlation to find the similarity between the features, then filtering by its correlation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#Using Pearson Correlation\r\n",
    "plt.figure(figsize=(12,10))\r\n",
    "cor = df.corr()\r\n",
    "#Correlation with output variable\r\n",
    "cor_target = abs(cor[\"target\"])\r\n",
    "#Selecting highly correlated features\r\n",
    "relevant_features = cor_target[cor_target>0.5]\r\n",
    "X_pearson = df.loc[:,relevant_features.index]\r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 864x720 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "X_GT = X.copy(deep=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#implements Banzhaf power index\r\n",
    "\r\n",
    "def banzhaf(weight, quota):\r\n",
    "\r\n",
    "    max_order = sum(weight)\r\n",
    "\r\n",
    "    polynomial = [1] + max_order*[0]               # create a list to hold the polynomial coefficients\r\n",
    "\r\n",
    "    current_order = 0                              # compute the polynomial coefficients\r\n",
    "    aux_polynomial = polynomial[:]\r\n",
    "    for i in range(len(weight)):\r\n",
    "        current_order = current_order + weight[i]\r\n",
    "        offset_polynomial = weight[i]*[0]+polynomial\r\n",
    "        for j in range(current_order+1):\r\n",
    "            aux_polynomial[j] = polynomial[j] + offset_polynomial[j]\r\n",
    "        polynomial = aux_polynomial[:]\r\n",
    "\r\n",
    "    banzhaf_power = len(weight)*[0]                                 # create a list to hold the Banzhaf Power for each voter\r\n",
    "    swings = quota*[0]                                              # create a list to compute the swings for each voter\r\n",
    "\r\n",
    "    for i in range(len(weight)):                                    # compute the Banzhaf Power\r\n",
    "        for j in range(quota):                                      # fill the swings list\r\n",
    "            if (j<weight[i]):\r\n",
    "                swings[j] = polynomial[j]\r\n",
    "            else:\r\n",
    "                swings[j] = polynomial[j] - swings[j-weight[i]]\r\n",
    "        for k in range(weight[i]):                                  # fill the Banzhaf Power vector\r\n",
    "            banzhaf_power[i] = banzhaf_power[i] + swings[quota-1-k]\r\n",
    "\r\n",
    "    # Normalize Index\r\n",
    "    total_power = float(sum(banzhaf_power))\r\n",
    "    banzhaf_index = map(lambda x: x / total_power, banzhaf_power)\r\n",
    "    \r\n",
    "    return banzhaf_index"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def payoff_function(weight, quota):\r\n",
    "    #TODO\r\n",
    "    print(\"payoff\")\r\n",
    "    return 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Input: A training sample O with feature space F and the target C\r\n",
    "# Output: Pv: Banzhaf power index vector of F.\r\n",
    "\r\n",
    "def GT_feature_evaluation(O, C, F):\r\n",
    "    pv = 0\r\n",
    "    banzhaf_arr = [] \r\n",
    "    for i, value in enumerate(F):\r\n",
    "        copy_set = O.copy(deep=True)\r\n",
    "        i_data = copy_set[value]\r\n",
    "        copy_set.drop(value, axis=1, inplace=True)\r\n",
    "        payoff_matrix = []\r\n",
    "        for j in copy_set.to_numpy():\r\n",
    "            payoff_matrix.append(payoff_function(i_data, j, C))\r\n",
    "        banzhaf_arr.append(banzhaf(payoff_matrix, C))\r\n",
    "    return banzhaf_arr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "banzhaf_power = []\r\n",
    "for feature in X_GT.columns:\r\n",
    "    banzhaf_power.append(banzhaf(X_GT[feature], 3))\r\n",
    "for idx, value in enumerate(banzhaf_power):\r\n",
    "    banzhaf_power[idx] = list(value)\r\n",
    "print(len(banzhaf_power))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dividing train and test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are using the train_test_split function from sklearn.model_selection to split the data into training and testing sets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=4)\r\n",
    "X_relieff_train, X_relieff_test, y_relieff_train, y_relieff_test = train_test_split( X_relieff, y, test_size=0.30, random_state=4)\r\n",
    "X_pearson_train, X_pearson_test, y_pearson_train, y_pearson_test = train_test_split( X_pearson, y, test_size=0.30, random_state=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training SVM model in each training set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "clf = svm.SVC()\r\n",
    "clf_relieff = svm.SVC()\r\n",
    "clf_pearson = svm.SVC()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting each model performance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "results = cross_validate(clf, X, y, cv=10, return_train_score=True)\r\n",
    "relieff_results = cross_validate(clf_relieff, X_relieff, y, cv=10, return_train_score=True)\r\n",
    "pearson_results = cross_validate(clf_pearson, X_pearson, y, cv=10, return_train_score=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "print(get_mean_scores(results, \"Control\"))\r\n",
    "print(get_mean_scores(relieff_results, \"RRelieff\"))\r\n",
    "print(get_mean_scores(pearson_results, \"Pearson\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'fit_time': 0.005098891258239746, 'score_time': 0.0031007051467895506, 'test_score': 0.990909090909091, 'train_score': 1.0, 'name': 'Control'}\n",
      "{'fit_time': 0.0007000446319580078, 'score_time': 0.00020003318786621094, 'test_score': 0.7300000000000001, 'train_score': 0.8390678694158076, 'name': 'Relieff'}\n",
      "{'fit_time': 0.0015004396438598633, 'score_time': 0.0007000923156738281, 'test_score': 0.9527272727272729, 'train_score': 1.0, 'name': 'Pearson'}\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33245f943a08e770773579a832d29284b103f4f52ecabefe7ebd4715f12a932d"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}